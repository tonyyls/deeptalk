/**
 * æ¨¡æ‹ŸGLM APIæœåŠ¡
 * ç”¨äºŽæœ¬åœ°å¼€å‘çŽ¯å¢ƒï¼Œæä¾›æ¨¡æ‹Ÿçš„AIå“åº”
 */

import express from 'express';
import cors from 'cors';

const app = express();
const PORT = 3002;

app.use(cors());
app.use(express.json());

// æ¨¡æ‹Ÿçš„AIå“åº”å†…å®¹
const mockResponses = [
  "ä½ å¥½ï¼æˆ‘æ˜¯DeepTalk AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è§£ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯äº¤æµã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
  "æ„Ÿè°¢æ‚¨ä½¿ç”¨DeepTalkï¼æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œä¸“é—¨è®¾è®¡æ¥ä¸Žç”¨æˆ·è¿›è¡Œæ™ºèƒ½å¯¹è¯ã€‚æˆ‘å¯ä»¥å›žç­”å„ç§é—®é¢˜ï¼Œæä¾›ä¿¡æ¯ï¼Œæˆ–è€…åªæ˜¯å’Œæ‚¨èŠå¤©ã€‚",
  "æ‚¨å¥½ï¼æˆ‘æ˜¯åŸºäºŽå¤§è¯­è¨€æ¨¡åž‹çš„AIåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨å¤„ç†æ–‡æœ¬ç›¸å…³çš„ä»»åŠ¡ï¼Œå›žç­”é—®é¢˜ï¼Œæˆ–è€…è¿›è¡Œåˆ›æ„è®¨è®ºã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥ä¸ºæ‚¨åšçš„å—ï¼Ÿ",
  "æ¬¢è¿Žä½¿ç”¨DeepTalk AIèŠå¤©åº”ç”¨ï¼æˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½å¯¹è¯ä¼™ä¼´ï¼Œå¯ä»¥å°±å„ç§è¯é¢˜ä¸Žæ‚¨äº¤æµã€‚è¯·éšæ—¶å‘Šè¯‰æˆ‘æ‚¨æƒ³èŠä»€ä¹ˆã€‚",
  "å¾ˆé«˜å…´è§åˆ°æ‚¨ï¼æˆ‘æ˜¯DeepTalkçš„AIåŠ©æ‰‹ï¼Œæ‹¥æœ‰å¹¿æ³›çš„çŸ¥è¯†åº“ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è§£å†³é—®é¢˜æˆ–è¿›è¡Œæœ‰è¶£çš„å¯¹è¯ã€‚"
];

// èŽ·å–éšæœºå“åº”
function getRandomResponse(userMessage) {
  // æ ¹æ®ç”¨æˆ·æ¶ˆæ¯å†…å®¹é€‰æ‹©åˆé€‚çš„å“åº”
  if (userMessage.includes('ä½ å¥½') || userMessage.includes('hello') || userMessage.includes('hi')) {
    return mockResponses[0];
  }
  
  if (userMessage.includes('ä»‹ç»') || userMessage.includes('è‡ªå·±')) {
    return mockResponses[1];
  }
  
  // é»˜è®¤éšæœºé€‰æ‹©
  const randomIndex = Math.floor(Math.random() * mockResponses.length);
  return mockResponses[randomIndex];
}

// æ¨¡æ‹Ÿæµå¼å“åº”
function createStreamResponse(message, res) {
  const response = getRandomResponse(message);
  const words = response.split('');
  let index = 0;

  // å‘é€å¼€å§‹ä¿¡å·
  res.write(`data: {"choices":[{"delta":{"content":""},"index":0}]}\n\n`);

  const interval = setInterval(() => {
    if (index < words.length) {
      const chunk = {
        choices: [{
          delta: {
            content: words[index]
          },
          index: 0
        }]
      };
      res.write(`data: ${JSON.stringify(chunk)}\n\n`);
      index++;
    } else {
      // å‘é€ç»“æŸä¿¡å·
      const endChunk = {
        choices: [{
          delta: {},
          index: 0,
          finish_reason: "stop"
        }],
        usage: {
          prompt_tokens: 10,
          completion_tokens: response.length,
          total_tokens: 10 + response.length
        }
      };
      res.write(`data: ${JSON.stringify(endChunk)}\n\n`);
      res.write(`data: [DONE]\n\n`);
      res.end();
      clearInterval(interval);
    }
  }, 50); // æ¯50mså‘é€ä¸€ä¸ªå­—ç¬¦
}

// GLM APIå…¼å®¹çš„èŠå¤©æŽ¥å£
app.post('/api/paas/v4/chat/completions', (req, res) => {
  console.log('Mock GLM API called:', req.body);
  
  const { messages, stream = false } = req.body;
  const userMessage = messages[messages.length - 1]?.content || '';

  if (stream) {
    // æµå¼å“åº”
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    res.setHeader('Access-Control-Allow-Origin', '*');
    
    createStreamResponse(userMessage, res);
  } else {
    // éžæµå¼å“åº”
    const response = getRandomResponse(userMessage);
    
    res.json({
      id: `chatcmpl-mock-${Date.now()}`,
      object: 'chat.completion',
      created: Math.floor(Date.now() / 1000),
      model: 'glm-4.6-mock',
      choices: [{
        index: 0,
        message: {
          role: 'assistant',
          content: response
        },
        finish_reason: 'stop'
      }],
      usage: {
        prompt_tokens: 10,
        completion_tokens: response.length,
        total_tokens: 10 + response.length
      }
    });
  }
});

// å¥åº·æ£€æŸ¥æŽ¥å£
app.get('/health', (req, res) => {
  res.json({ status: 'ok', service: 'mock-glm-api' });
});

app.listen(PORT, () => {
  console.log(`ðŸ¤– Mock GLM API server running on http://localhost:${PORT}`);
  console.log(`ðŸ“¡ API endpoint: http://localhost:${PORT}/api/paas/v4/chat/completions`);
});

export default app;